# æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹åŸºå‡†æµ‹è¯•

æœ¬ç›®å½•åŒ…å«ç”¨äºè¯„ä¼°æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ç®—æ³•çš„åŸºå‡†æµ‹è¯•ä»£ç ã€‚

## ä¸»è¦åŠŸèƒ½

### 1. è¿è¡ŒåŸºå‡†æµ‹è¯• (`run_benchmark.py`)

è¿è¡Œå¤šä¸ªæ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ç®—æ³•ï¼Œè¯„ä¼°å®ƒä»¬åœ¨å•å˜é‡æˆ–å¤šå˜é‡æ•°æ®é›†ä¸Šçš„æ€§èƒ½ã€‚

**æ–°å¢åŠŸèƒ½ï¼š**
- æ”¯æŒå¤šæ¬¡è¿è¡Œå®éªŒè¿›è¡Œç¨³å®šæ€§åˆ†æ
- æ”¶é›†å’Œä¿å­˜æ¨¡å‹å‚æ•°é‡å’Œå¤§å°ä¿¡æ¯
- åœ¨å•å˜é‡å’Œå¤šå˜é‡æ•°æ®é›†ä¸Šç‹¬ç«‹è¿è¡Œ
- è‡ªåŠ¨ä¿å­˜ç»Ÿè®¡ä¿¡æ¯å’Œè¿è¡Œç»“æœ

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```bash
# åœ¨å•å˜é‡å’Œå¤šå˜é‡æ•°æ®é›†ä¸Šè¿è¡ŒåŸºå‡†æµ‹è¯•ï¼Œæ¯ä¸ª2æ¬¡å®éªŒ
python run_benchmark.py --num_runs 2 --dataset_type Both

# ä»…åœ¨å•å˜é‡æ•°æ®é›†ä¸Šè¿è¡Œ
python run_benchmark.py --num_runs 2 --dataset_type Univariate

# ä»…åœ¨å¤šå˜é‡æ•°æ®é›†ä¸Šè¿è¡Œ
python run_benchmark.py --num_runs 2 --dataset_type Multivariate 
```

**å‚æ•°è¯´æ˜ï¼š**

- `--uni_dataset`: å•å˜é‡æ•°æ®é›†æ–‡ä»¶å
- `--multi_dataset`: å¤šå˜é‡æ•°æ®é›†æ–‡ä»¶å
- `--uni_dataset_dir`: å•å˜é‡æ•°æ®é›†ç›®å½•
- `--multi_dataset_dir`: å¤šå˜é‡æ•°æ®é›†ç›®å½•
- `--save_dir`: ä¿å­˜ç»“æœçš„ç›®å½•
- `--log_file`: æ—¥å¿—æ–‡ä»¶è·¯å¾„
- `--num_runs`: è¿è¡Œå®éªŒçš„æ¬¡æ•°ï¼ˆé»˜è®¤2æ¬¡ï¼‰
- `--dataset_type`: æ•°æ®é›†ç±»å‹ï¼ˆUnivariate/Multivariate/Bothï¼‰

### 2. ç»“æœåˆ†æ (`benchmark_analysis.py`)

åˆ†æåŸºå‡†æµ‹è¯•ç»“æœï¼Œç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å’Œç»Ÿè®¡åˆ†æã€‚

**ä¸»è¦åŠŸèƒ½ï¼š**
- åŠ è½½å’Œåˆ†æå¤šæ¬¡è¿è¡Œçš„å®éªŒç»“æœ
- ç»Ÿè®¡åˆ†æå„ç®—æ³•åœ¨ä¸åŒæŒ‡æ ‡ä¸Šçš„æ€§èƒ½
- ç”Ÿæˆç¨³å®šæ€§åˆ†æï¼ˆæ ‡å‡†å·®ã€å˜å¼‚ç³»æ•°ï¼‰
- åˆ†ææ¨¡å‹å‚æ•°é‡å’Œå¤§å°
- ç»˜åˆ¶ä¸´ç•Œå·®å¼‚å›¾ã€ç®±çº¿å›¾ç­‰å¯è§†åŒ–
- ç”Ÿæˆç»¼åˆPDFæŠ¥å‘Š

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```bash
# åˆ†ææŒ‡å®šç›®å½•ä¸­çš„æ‰€æœ‰ç»“æœ
python benchmark_analysis.py --results_dir eval/benchmark --save_dir analysis_results

# ä»…åˆ†æå•å˜é‡æ•°æ®é›†ç»“æœ
python benchmark_analysis.py --results_dir eval/benchmark --save_dir analysis_results --dataset_type Univariate
```

**å‚æ•°è¯´æ˜ï¼š**

- `--results_dir`: ç»“æœç›®å½•è·¯å¾„
- `--save_dir`: ä¿å­˜åˆ†æç»“æœçš„ç›®å½•
- `--dataset_type`: è¦åˆ†æçš„æ•°æ®é›†ç±»å‹ï¼ˆUnivariate/Multivariate/Bothï¼‰
- `--alpha`: ç»Ÿè®¡æ˜¾è‘—æ€§æ°´å¹³ï¼ˆé»˜è®¤0.05ï¼‰

## è¯„ä¼°æŒ‡æ ‡

åŸºå‡†æµ‹è¯•è¯„ä¼°ä½¿ç”¨ä»¥ä¸‹æŒ‡æ ‡ï¼š
- `AUC-PR`: ç²¾å‡†ç‡-å¬å›ç‡æ›²çº¿ä¸‹é¢ç§¯
- `AUC-ROC`: ROCæ›²çº¿ä¸‹é¢ç§¯
- `VUS-PR`: Volume Under Surface for PR
- `VUS-ROC`: Volume Under Surface for ROC
- `Standard-F1`: æ ‡å‡†F1åˆ†æ•°
- `PA-F1`: ç‚¹è°ƒæ•´F1åˆ†æ•°
- `Event-based-F1`: äº‹ä»¶çº§F1åˆ†æ•°
- `R-based-F1`: R-based F1åˆ†æ•°
- `Affiliation-F`: Affiliation Fåˆ†æ•°

## ç®—æ³•åˆ—è¡¨

æ”¯æŒçš„ç®—æ³•æŒ‰ç±»å‹åˆ’åˆ†:

### é‡æ„å‹
- AutoEncoder
- PCA
- USAD
- OmniAnomaly

### é¢„æµ‹å‹
- LSTMAD
- DLinear

### æ’è¡¥å‹
- Donut

### èšç±»å‹
- KMeansAD
- LOF
- OCSVM

### æ··åˆå‹
- AnomalyTransformer

## åˆ†æè¾“å‡º

è¿è¡Œ`benchmark_analysis.py`åï¼Œå°†ç”Ÿæˆä»¥ä¸‹è¾“å‡ºï¼š
- ç®—æ³•æ€§èƒ½å¯¹æ¯”å›¾è¡¨ï¼ˆç®±çº¿å›¾ï¼‰
- ä¸´ç•Œå·®å¼‚å›¾ï¼ˆç®—æ³•æ’åï¼‰
- ç¨³å®šæ€§åˆ†æï¼ˆçƒ­åŠ›å›¾ã€å˜å¼‚ç³»æ•°ï¼‰
- æ¨¡å‹å¤§å°å’Œå‚æ•°é‡åˆ†æ
- ç»¼åˆPDFæŠ¥å‘Š

## æ³¨æ„äº‹é¡¹

- å¤šæ¬¡è¿è¡Œå®éªŒæ—¶ï¼Œæ¯æ¬¡ä½¿ç”¨ä¸åŒçš„éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é æ€§
- åˆ†æç»“æœæ—¶ï¼Œé»˜è®¤ä¼šåŠ è½½æ‰€æœ‰å¯ç”¨ç»“æœæ–‡ä»¶
- å¯ä»¥é€šè¿‡ `--dataset_type` å‚æ•°é€‰æ‹©ä»…åˆ†æå•å˜é‡æˆ–å¤šå˜é‡ç»“æœ

### Scripts for running experiments/develop new methods in TSB-AD

* Hper-parameter Tuning: HP_Tuning_U/M.py

* Benchmark Evaluation: Run_Detector_U/M.py

* `benchmark_eval_results/`: Evaluation results of anomaly detectors across different time series in TSB-AD
    * All time series are normalized by z-score by default

* Develop your own algorithm: Run_Custom_Detector.py
    * Step 1: Implement `Custom_AD` class
    * Step 2: Implement model wrapper function `run_Custom_AD_Unsupervised` or `run_Custom_AD_Semisupervised`
    * Step 3: Specify `Custom_AD_HP` hyperparameter dict
    * Step 4: Run the custom algorithm either `run_Custom_AD_Unsupervised` or `run_Custom_AD_Semisupervised`
    * Step 5: Apply threshold to the anomaly score (if any)

ğŸª§ How to commit your own algorithm to TSB-AD: you can send us the Run_Custom_Detector.py (replace Custom_Detector with the model name) to us via (i) [email](liu.11085@osu.edu) or (ii) open a pull request and add the file to `benchmark_exp` folder in `TSB-AD-algo` branch. We will test and evaluate the algorithm and include it in our [leaderboard](https://thedatumorg.github.io/TSB-AD/).

* Run_My_Detector.py: Run your own detector